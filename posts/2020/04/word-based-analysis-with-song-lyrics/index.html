<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Word-based analysis with song lyrics | Karn Wong</title><meta name=keywords content="data analysis"><meta name=description content="I listen to a lot of music, mostly symphonic heavy metal. What&rsquo;s interesting is that in this genre, each album often has different themes, also each band focus on different topics in terms of lyrics. For instance, Nightwish focuses on nature, and their Imaginaerum album focuses on evolution. So I thought it would be interesting if I apply various text analysis methods to the lyrics, which resulted in this article. Github link here!"><meta name=author content="Karn Wong"><link rel=canonical href=https://www.karnwong.me/posts/2020/04/word-based-analysis-with-song-lyrics/><link crossorigin=anonymous href=/assets/css/stylesheet.bc1149f4a72aa4858d3a9f71462f75e5884ffe8073ea9d6d5761d5663d651e20.css integrity="sha256-vBFJ9KcqpIWNOp9xRi915YhP/oBz6p1tV2HVZj1lHiA=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://www.karnwong.me/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://www.karnwong.me/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://www.karnwong.me/favicon-32x32.png><link rel=apple-touch-icon href=https://www.karnwong.me/apple-touch-icon.png><link rel=mask-icon href=https://www.karnwong.me/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-8CYMFC0KZ9"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-8CYMFC0KZ9",{anonymize_ip:!1})}</script><meta property="og:title" content="Word-based analysis with song lyrics"><meta property="og:description" content="I listen to a lot of music, mostly symphonic heavy metal. What&rsquo;s interesting is that in this genre, each album often has different themes, also each band focus on different topics in terms of lyrics. For instance, Nightwish focuses on nature, and their Imaginaerum album focuses on evolution. So I thought it would be interesting if I apply various text analysis methods to the lyrics, which resulted in this article. Github link here!"><meta property="og:type" content="article"><meta property="og:url" content="https://www.karnwong.me/posts/2020/04/word-based-analysis-with-song-lyrics/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2020-04-15T17:00:00+00:00"><meta property="article:modified_time" content="2020-04-15T17:00:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Word-based analysis with song lyrics"><meta name=twitter:description content="I listen to a lot of music, mostly symphonic heavy metal. What&rsquo;s interesting is that in this genre, each album often has different themes, also each band focus on different topics in terms of lyrics. For instance, Nightwish focuses on nature, and their Imaginaerum album focuses on evolution. So I thought it would be interesting if I apply various text analysis methods to the lyrics, which resulted in this article. Github link here!"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://www.karnwong.me/posts/"},{"@type":"ListItem","position":2,"name":"Word-based analysis with song lyrics","item":"https://www.karnwong.me/posts/2020/04/word-based-analysis-with-song-lyrics/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Word-based analysis with song lyrics","name":"Word-based analysis with song lyrics","description":"I listen to a lot of music, mostly symphonic heavy metal. What\u0026rsquo;s interesting is that in this genre, each album often has different themes, also each band focus on different topics in terms of lyrics. For instance, Nightwish focuses on nature, and their Imaginaerum album focuses on evolution. So I thought it would be interesting if I apply various text analysis methods to the lyrics, which resulted in this article. Github link here!","keywords":["data analysis"],"articleBody":"I listen to a lot of music, mostly symphonic heavy metal. What’s interesting is that in this genre, each album often has different themes, also each band focus on different topics in terms of lyrics. For instance, Nightwish focuses on nature, and their Imaginaerum album focuses on evolution. So I thought it would be interesting if I apply various text analysis methods to the lyrics, which resulted in this article. Github link here!\nTechniques used tokenization stemming and lemming topic modeling Import modules from collections import Counter import matplotlib.colors as colors import matplotlib.pyplot as plt import numpy as np import pandas as pd import seaborn as sns from nltk import word_tokenize ## from nltk.corpus import stopwords from nltk.stem import PorterStemmer from sklearn.decomposition import NMF, LatentDirichletAllocation from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer sns.set() Import data generated from 01_get_data.py In this step, I import raw data and convert raw year into a decade, for instance 1993 is in 1990s. I won’t be doing analysis by decades, because in heavy metal it doesn’t follow the trend much. But I include it here in case you are working on pop artists. In addition, the differences by year may not be that large, so it makes sense to see it in terms of decades.\ndf = pd.read_csv('lyrics.csv') ## dop song duplicates from the same artist df.drop_duplicates(subset=['artist', 'title'], inplace=True) ## tokenize, remove stopwords, stemming and lemming ## stop_words = set(stopwords.words('english')) with open('english.txt', 'r') as f: stop_words = [i.strip() for i in f.readlines()] ps = PorterStemmer() df['tokens'] = df.lyrics.apply( lambda x: [ps.stem(w) for w in word_tokenize(x.lower()) if (not w in stop_words) and (not \"'\" in w) and (len(w) \u003e 1) ]) ## count words df['word_count'] = df.tokens.apply(lambda x: len(x)) ## count unique words df['unique_word_count'] = df.tokens.apply(lambda x: len(set(x))) ## remove outliers df = df[df.word_count\u003e10] ## set decade df['year'] = df.year.astype(int) df['1990s'] = np.where( ((1990\u003c=df.year) \u0026 (df.year \u003c=1999)), '1990s', None ) df['2000s'] = np.where( ((2000\u003c=df.year) \u0026 (df.year \u003c=2009)), '2000s', None ) df['2010s'] = np.where( ((2010\u003c=df.year) \u0026 (df.year \u003c=2019)), '2010s', None ) df['2020s'] = np.where( ((2020\u003c=df.year) \u0026 (df.year \u003c=2029)), '2020s', None ) df['decade'] = df['1990s'].combine_first(df['2000s']).combine_first(df['2010s']).combine_first(df['2020s']) ## drop unused columns df = df.drop(columns=['1990s', '2000s', '2010s', '2020s']) df artist album title lyrics year tokens word_count unique_word_count decade 0 Nightwish Angels Fall First Elvenpath (In the sh 1996 [‘shelter’, ‘shade’, ‘forest’, …] 121 90 1990s 1 Nightwish Angels Fall First Beauty And The Beast Remember t 1996 [‘rememb’, ‘danc’, ‘share’, …] 74 56 1990s 2 Nightwish Angels Fall First The Carpenter Who are yo 1996 [‘condemn’, ‘shine’, ‘salvat’, …] 74 42 1990s 3 Nightwish Angels Fall First Astral Romance A nocturna 1996 [’nocturn’, ‘concerto’, ‘candlelight’, …] 69 68 1990s 4 Nightwish Angels Fall First Angels Fall First An angelfa 1996 [‘angelfac’, ‘smile’, ‘headlin’, …] 68 49 1990s 5 Nightwish Angels Fall First Tutankhamen As the sun 1996 [‘sun’, ‘set’, ‘pyramid’, …] 67 41 1990s 6 Nightwish Angels Fall First Nymphomaniac Fantasia The scent 1996 [‘scent’, ‘woman’, ‘…’] 29 28 1990s 7 Nightwish Angels Fall First Know Why The Nightingale Sings What does 1996 [‘fall’, ‘feel’, ‘boy’, …] 49 47 1990s 8 Nightwish Angels Fall First Lappi (Lapland) Part 1: Er 1996 [’erämaajärvi’, ‘kautta’, ’erämaajärven’, …] 63 54 1990s 9 Nightwish Angels Fall First Once Upon A Troubadour A lonely b 1996 [’lone’, ‘bard’, ‘wander’, …] 91 62 1990s Explore relationship From this plot, I can see that there is a correlation between word_count and unique_word_count, that is, they go in the same direction. The higher the word_count, the higher unique_word_count and vice versa.\ng = sns.PairGrid(df[['word_count', 'unique_word_count']]) g.map(plt.scatter) Boxplot We can use either word_count or unique_word_count, since they go in the same direction, except the values from unique_word_count will be higher, but it is proportional to word_count\nBoxplot represents data distribution in quartiles, in which the the box-y area is in middle of the distribution (think of a bell curve, the box-y area is right around the peak, padded a bit to left and right), and the line-y area is the left/right edge of the curve. The scattered points are outliers, meaning they are too different from the rest of the dataset.\nFrom this figure, I can see that Nightwish has a very large outlier, seeing one data point is in 350 range. Myrath has the least words, and Linkin Park has the most. For Linkin Park, it can be attributed to the fact that their lyrics contain rap verses. As for Nightwish outliers, some of their songs contain very lengthy spoken parts.\nplt.figure(figsize=(10,7)) sns.boxplot(x=\"word_count\", y=\"artist\", data=df, orient='h') Most common words In this step, I count how many times a word occur per dataset, then plot a bar graph for each. For the bands I usually listen to, each album has a theme, so it’s very probable that each album would have different set of most common words.\ndef word_vector(df): ########## make a list of all unique words all_words = [] for i in df.tokens: all_words.extend(set(i)) all_words = set(all_words) ########## make tf/idf word_count = df.tokens.apply(lambda x: Counter(x)) word_count = pd.DataFrame(word_count.to_list()) ########## get sum for each unique word wordcount_sum = [] for i in word_count.columns: wordcount_sum.append({ 'word': i, 'count': word_count[i].sum() }) wordcount_sum = pd.DataFrame(wordcount_sum) wordcount_sum = wordcount_sum[wordcount_sum['count']!=0] wordcount_sum.sort_values(by='count', ascending=False, inplace=True) ########## return wordcount_sum.head(10) ## get wordcount for each group, this way the word_vector function is not getting messy wordcount_group = [] ################## adjust filters here artist = 'Epica' group = 'album' # album, decade ################## df_temp = df[df.artist==artist] for i in df_temp[group].unique(): chunk = word_vector(df_temp[df[group]==i]) chunk[group] = i wordcount_group.append(chunk) wordcount_group = pd.concat(wordcount_group) ## plot fig, axs = plt.subplots(len(wordcount_group[group].unique()), figsize=(13,53)) # adjust figure size here if it's too cramped for index, i in enumerate(wordcount_group[group].unique()): temp = wordcount_group[wordcount_group[group]==i] axs[index].bar(temp['word'], temp['count']) axs[index].set_title(i) From the above image, you can see that the top words don’t vary much between albums. So I can conclude that Epica have a consistent lyric themes, but if you listen you can hear that their melody changes every album. For instance, in The Divine Conspiracy, it’s very classical and oriental oriented, but in The Holographic Principle it gets heavier.\nBut that’s only variations between albums from one artist. What if we do the same but with each artist instead?\nwordcount_group = [] df_temp = df group = 'artist' for i in df_temp[group].unique(): chunk = word_vector(df_temp[df[group]==i]) chunk[group] = i wordcount_group.append(chunk) wordcount_group = pd.concat(wordcount_group) fig, axs = plt.subplots(len(wordcount_group[group].unique()), figsize=(13,80)) # adjust figure size here if it's too cramped for index, i in enumerate(wordcount_group[group].unique()): temp = wordcount_group[wordcount_group[group]==i] axs[index].bar(temp['word'], temp['count']) axs[index].set_title(i) Whoops. Still more or less the same. But if you look carefully, Powerwolf stands out because their lyrical themes are werewolves and myths.\nTopic modeling So I change the tactics a bit by using topic modeling instead of seeing just the top words count. This way, the model and extract group of words that said to be the essence belonging to each cluster. I use both NMF and LDA here for comparison. Here, I tell the model to read lyrics from four artists, then try to group into clusters and finding main words from each, but I’m not telling it which document belongs to which artist.\ndef display_topics(model, feature_names, no_top_words): topic_words = [] for topic_idx, topic in enumerate(model.components_): print (\"Topic %d:\" % (topic_idx)) topic = (\" \".join([feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]])) print('\\t' + topic) topic_words.append(topic) return topic_words ## define temp dataframe here temp = df.query('artist == \"Visions of Atlantis\" or\\ artist == \"Lacuna Coil\" or\\ artist == \"Epica\" or\\ artist == \"Nightwish\"') ## define parameters no_features = 1000 no_topics = len(temp.artist.unique()) # set album count as number of topics no_top_words = 15 ## create word matrix tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, max_features=no_features, stop_words='english') tfidf = tfidf_vectorizer.fit_transform(temp.lyrics) tfidf_feature_names = tfidf_vectorizer.get_feature_names() print('========== NMF ==========') nmf = NMF(n_components=no_topics, random_state=1, alpha=.1, l1_ratio=.5, init='nndsvd').fit(tfidf) topic_words = display_topics(nmf, tfidf_feature_names, no_top_words) ========== NMF ========== Topic 0: ll time life way light come live free just feel inside ve day let world Topic 1: love heart night wish forever hate soul dream oh art rest heaven need kiss lust Topic 2: away run far stay inside journey dream fade just wash felt destruction escape falling walked Topic 3: don know wanna want just feel say care hate goes cause liar let look reason print('========== LDA ==========') lda = LatentDirichletAllocation(n_components=no_topics, max_iter=5, learning_method='online', learning_offset=50.,random_state=0).fit(tfidf) topic_words = display_topics(lda, tfidf_feature_names, no_top_words) ========== LDA ========== Topic 0: distance don beautiful let today cold look guide read world way faith wish mind heart Topic 1: est tale feels talking drives wall wishmaster disciple bone mad searching free master apprentice sing Topic 2: love heart ll hearts time world fight let come night know shadows try eyes mind Topic 3: leaving ll healing endless sed died walk desire life nos ne moment die nostra like From NMF, I can tell that:\nTopic 0 is Epica Topic 1 is Nightwish Topic 2 is Visions of Atlantis Topic 3 is Lacuna Coil I think NMF performs better in this case 😆\nThere are some instances LDA performs better, but generally unless it’s very obvious from the start, sometimes you use different models and see which performs best for a given dataset.\n","wordCount":"1498","inLanguage":"en","datePublished":"2020-04-15T17:00:00Z","dateModified":"2020-04-15T17:00:00Z","author":{"@type":"Person","name":"Karn Wong"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://www.karnwong.me/posts/2020/04/word-based-analysis-with-song-lyrics/"},"publisher":{"@type":"Organization","name":"Karn Wong","logo":{"@type":"ImageObject","url":"https://www.karnwong.me/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://www.karnwong.me/ accesskey=h title="Karn Wong (Alt + H)">Karn Wong</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://www.karnwong.me/about/ title=About><span>About</span></a></li><li><a href=https://www.karnwong.me/posts title=Posts><span>Posts</span></a></li><li><a href=https://www.karnwong.me/projects/ title=Projects><span>Projects</span></a></li><li><a href=https://www.karnwong.me/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://www.karnwong.me/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://www.karnwong.me/>Home</a>&nbsp;»&nbsp;<a href=https://www.karnwong.me/posts/>Posts</a></div><h1 class=post-title>Word-based analysis with song lyrics</h1><div class=post-meta><span title='2020-04-15 17:00:00 +0000 UTC'>April 15, 2020</span>&nbsp;·&nbsp;8 min&nbsp;·&nbsp;Karn Wong</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#techniques-used aria-label="Techniques used">Techniques used</a></li><li><a href=#import-modules aria-label="Import modules">Import modules</a></li><li><a href=#import-data-generated-from-01_get_datapy aria-label="Import data generated from 01_get_data.py">Import data generated from 01_get_data.py</a></li><li><a href=#explore-relationship aria-label="Explore relationship">Explore relationship</a></li><li><a href=#boxplot aria-label=Boxplot>Boxplot</a></li><li><a href=#most-common-words aria-label="Most common words">Most common words</a></li><li><a href=#topic-modeling aria-label="Topic modeling">Topic modeling</a></li></ul></div></details></div><div class=post-content><p>I listen to a lot of music, mostly symphonic heavy metal. What&rsquo;s interesting is that in this genre, each album often has different themes, also each band focus on different topics in terms of lyrics. For instance, Nightwish focuses on nature, and their Imaginaerum album focuses on evolution. So I thought it would be interesting if I apply various text analysis methods to the lyrics, which resulted in this article. Github link <a href=https://github.com/kahnwong/lyrics_visualization>here</a>!</p><h2 id=techniques-used>Techniques used<a hidden class=anchor aria-hidden=true href=#techniques-used>#</a></h2><ul><li>tokenization</li><li>stemming and lemming</li><li>topic modeling</li></ul><h2 id=import-modules>Import modules<a hidden class=anchor aria-hidden=true href=#import-modules>#</a></h2><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> collections <span style=color:#f92672>import</span> Counter
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> matplotlib.colors <span style=color:#66d9ef>as</span> colors
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> matplotlib.pyplot <span style=color:#66d9ef>as</span> plt
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> pandas <span style=color:#66d9ef>as</span> pd
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> seaborn <span style=color:#66d9ef>as</span> sns
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> nltk <span style=color:#f92672>import</span> word_tokenize
</span></span><span style=display:flex><span><span style=color:#75715e>## from nltk.corpus import stopwords</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> nltk.stem <span style=color:#f92672>import</span> PorterStemmer
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.decomposition <span style=color:#f92672>import</span> NMF, LatentDirichletAllocation
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.feature_extraction.text <span style=color:#f92672>import</span> CountVectorizer, TfidfVectorizer
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>sns<span style=color:#f92672>.</span>set()
</span></span></code></pre></div><h2 id=import-data-generated-from-01_get_datapy>Import data generated from 01_get_data.py<a hidden class=anchor aria-hidden=true href=#import-data-generated-from-01_get_datapy>#</a></h2><p>In this step, I import raw data and convert raw year into a decade, for instance 1993 is in 1990s. I won&rsquo;t be doing analysis by decades, because in heavy metal it doesn&rsquo;t follow the trend much. But I include it here in case you are working on pop artists. In addition, the differences by year may not be that large, so it makes sense to see it in terms of decades.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>df <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>read_csv(<span style=color:#e6db74>&#39;lyrics.csv&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>## dop song duplicates from the same artist</span>
</span></span><span style=display:flex><span>df<span style=color:#f92672>.</span>drop_duplicates(subset<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#39;artist&#39;</span>, <span style=color:#e6db74>&#39;title&#39;</span>], inplace<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>## tokenize, remove stopwords, stemming and lemming</span>
</span></span><span style=display:flex><span><span style=color:#75715e>## stop_words = set(stopwords.words(&#39;english&#39;))</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>with</span> open(<span style=color:#e6db74>&#39;english.txt&#39;</span>, <span style=color:#e6db74>&#39;r&#39;</span>) <span style=color:#66d9ef>as</span> f:
</span></span><span style=display:flex><span>    stop_words <span style=color:#f92672>=</span> [i<span style=color:#f92672>.</span>strip() <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> f<span style=color:#f92672>.</span>readlines()]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>ps <span style=color:#f92672>=</span> PorterStemmer()
</span></span><span style=display:flex><span>df[<span style=color:#e6db74>&#39;tokens&#39;</span>] <span style=color:#f92672>=</span> df<span style=color:#f92672>.</span>lyrics<span style=color:#f92672>.</span>apply(
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>lambda</span> x: [ps<span style=color:#f92672>.</span>stem(w)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> w <span style=color:#f92672>in</span> word_tokenize(x<span style=color:#f92672>.</span>lower())
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span>
</span></span><span style=display:flex><span>         (<span style=color:#f92672>not</span> w <span style=color:#f92672>in</span> stop_words) <span style=color:#f92672>and</span>
</span></span><span style=display:flex><span>         (<span style=color:#f92672>not</span> <span style=color:#e6db74>&#34;&#39;&#34;</span> <span style=color:#f92672>in</span> w) <span style=color:#f92672>and</span>
</span></span><span style=display:flex><span>         (len(w) <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>    ])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>## count words</span>
</span></span><span style=display:flex><span>df[<span style=color:#e6db74>&#39;word_count&#39;</span>] <span style=color:#f92672>=</span> df<span style=color:#f92672>.</span>tokens<span style=color:#f92672>.</span>apply(<span style=color:#66d9ef>lambda</span> x: len(x))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>## count unique words</span>
</span></span><span style=display:flex><span>df[<span style=color:#e6db74>&#39;unique_word_count&#39;</span>] <span style=color:#f92672>=</span> df<span style=color:#f92672>.</span>tokens<span style=color:#f92672>.</span>apply(<span style=color:#66d9ef>lambda</span> x: len(set(x)))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>## remove outliers</span>
</span></span><span style=display:flex><span>df <span style=color:#f92672>=</span> df[df<span style=color:#f92672>.</span>word_count<span style=color:#f92672>&gt;</span><span style=color:#ae81ff>10</span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>## set decade</span>
</span></span><span style=display:flex><span>df[<span style=color:#e6db74>&#39;year&#39;</span>] <span style=color:#f92672>=</span> df<span style=color:#f92672>.</span>year<span style=color:#f92672>.</span>astype(int)
</span></span><span style=display:flex><span>df[<span style=color:#e6db74>&#39;1990s&#39;</span>] <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>where(
</span></span><span style=display:flex><span>                ((<span style=color:#ae81ff>1990</span><span style=color:#f92672>&lt;=</span>df<span style=color:#f92672>.</span>year) <span style=color:#f92672>&amp;</span> (df<span style=color:#f92672>.</span>year <span style=color:#f92672>&lt;=</span><span style=color:#ae81ff>1999</span>)),
</span></span><span style=display:flex><span>                <span style=color:#e6db74>&#39;1990s&#39;</span>,
</span></span><span style=display:flex><span>                <span style=color:#66d9ef>None</span>
</span></span><span style=display:flex><span>            )
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>df[<span style=color:#e6db74>&#39;2000s&#39;</span>] <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>where(
</span></span><span style=display:flex><span>                ((<span style=color:#ae81ff>2000</span><span style=color:#f92672>&lt;=</span>df<span style=color:#f92672>.</span>year) <span style=color:#f92672>&amp;</span> (df<span style=color:#f92672>.</span>year <span style=color:#f92672>&lt;=</span><span style=color:#ae81ff>2009</span>)),
</span></span><span style=display:flex><span>                <span style=color:#e6db74>&#39;2000s&#39;</span>,
</span></span><span style=display:flex><span>                <span style=color:#66d9ef>None</span>
</span></span><span style=display:flex><span>            )
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>df[<span style=color:#e6db74>&#39;2010s&#39;</span>] <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>where(
</span></span><span style=display:flex><span>                ((<span style=color:#ae81ff>2010</span><span style=color:#f92672>&lt;=</span>df<span style=color:#f92672>.</span>year) <span style=color:#f92672>&amp;</span> (df<span style=color:#f92672>.</span>year <span style=color:#f92672>&lt;=</span><span style=color:#ae81ff>2019</span>)),
</span></span><span style=display:flex><span>                <span style=color:#e6db74>&#39;2010s&#39;</span>,
</span></span><span style=display:flex><span>                <span style=color:#66d9ef>None</span>
</span></span><span style=display:flex><span>            )
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>df[<span style=color:#e6db74>&#39;2020s&#39;</span>] <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>where(
</span></span><span style=display:flex><span>                ((<span style=color:#ae81ff>2020</span><span style=color:#f92672>&lt;=</span>df<span style=color:#f92672>.</span>year) <span style=color:#f92672>&amp;</span> (df<span style=color:#f92672>.</span>year <span style=color:#f92672>&lt;=</span><span style=color:#ae81ff>2029</span>)),
</span></span><span style=display:flex><span>                <span style=color:#e6db74>&#39;2020s&#39;</span>,
</span></span><span style=display:flex><span>                <span style=color:#66d9ef>None</span>
</span></span><span style=display:flex><span>            )
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>df[<span style=color:#e6db74>&#39;decade&#39;</span>] <span style=color:#f92672>=</span> df[<span style=color:#e6db74>&#39;1990s&#39;</span>]<span style=color:#f92672>.</span>combine_first(df[<span style=color:#e6db74>&#39;2000s&#39;</span>])<span style=color:#f92672>.</span>combine_first(df[<span style=color:#e6db74>&#39;2010s&#39;</span>])<span style=color:#f92672>.</span>combine_first(df[<span style=color:#e6db74>&#39;2020s&#39;</span>])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>## drop unused columns</span>
</span></span><span style=display:flex><span>df <span style=color:#f92672>=</span> df<span style=color:#f92672>.</span>drop(columns<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#39;1990s&#39;</span>, <span style=color:#e6db74>&#39;2000s&#39;</span>, <span style=color:#e6db74>&#39;2010s&#39;</span>, <span style=color:#e6db74>&#39;2020s&#39;</span>])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>df
</span></span></code></pre></div><table><thead><tr><th style=text-align:right></th><th style=text-align:left>artist</th><th style=text-align:left>album</th><th style=text-align:left>title</th><th style=text-align:left>lyrics</th><th style=text-align:right>year</th><th style=text-align:left>tokens</th><th style=text-align:right>word_count</th><th style=text-align:right>unique_word_count</th><th style=text-align:left>decade</th></tr></thead><tbody><tr><td style=text-align:right>0</td><td style=text-align:left>Nightwish</td><td style=text-align:left>Angels Fall First</td><td style=text-align:left>Elvenpath</td><td style=text-align:left>(In the sh</td><td style=text-align:right>1996</td><td style=text-align:left>[&lsquo;shelter&rsquo;, &lsquo;shade&rsquo;, &lsquo;forest&rsquo;, &mldr;]</td><td style=text-align:right>121</td><td style=text-align:right>90</td><td style=text-align:left>1990s</td></tr><tr><td style=text-align:right>1</td><td style=text-align:left>Nightwish</td><td style=text-align:left>Angels Fall First</td><td style=text-align:left>Beauty And The Beast</td><td style=text-align:left>Remember t</td><td style=text-align:right>1996</td><td style=text-align:left>[&lsquo;rememb&rsquo;, &lsquo;danc&rsquo;, &lsquo;share&rsquo;, &mldr;]</td><td style=text-align:right>74</td><td style=text-align:right>56</td><td style=text-align:left>1990s</td></tr><tr><td style=text-align:right>2</td><td style=text-align:left>Nightwish</td><td style=text-align:left>Angels Fall First</td><td style=text-align:left>The Carpenter</td><td style=text-align:left>Who are yo</td><td style=text-align:right>1996</td><td style=text-align:left>[&lsquo;condemn&rsquo;, &lsquo;shine&rsquo;, &lsquo;salvat&rsquo;, &mldr;]</td><td style=text-align:right>74</td><td style=text-align:right>42</td><td style=text-align:left>1990s</td></tr><tr><td style=text-align:right>3</td><td style=text-align:left>Nightwish</td><td style=text-align:left>Angels Fall First</td><td style=text-align:left>Astral Romance</td><td style=text-align:left>A nocturna</td><td style=text-align:right>1996</td><td style=text-align:left>[&rsquo;nocturn&rsquo;, &lsquo;concerto&rsquo;, &lsquo;candlelight&rsquo;, &mldr;]</td><td style=text-align:right>69</td><td style=text-align:right>68</td><td style=text-align:left>1990s</td></tr><tr><td style=text-align:right>4</td><td style=text-align:left>Nightwish</td><td style=text-align:left>Angels Fall First</td><td style=text-align:left>Angels Fall First</td><td style=text-align:left>An angelfa</td><td style=text-align:right>1996</td><td style=text-align:left>[&lsquo;angelfac&rsquo;, &lsquo;smile&rsquo;, &lsquo;headlin&rsquo;, &mldr;]</td><td style=text-align:right>68</td><td style=text-align:right>49</td><td style=text-align:left>1990s</td></tr><tr><td style=text-align:right>5</td><td style=text-align:left>Nightwish</td><td style=text-align:left>Angels Fall First</td><td style=text-align:left>Tutankhamen</td><td style=text-align:left>As the sun</td><td style=text-align:right>1996</td><td style=text-align:left>[&lsquo;sun&rsquo;, &lsquo;set&rsquo;, &lsquo;pyramid&rsquo;, &mldr;]</td><td style=text-align:right>67</td><td style=text-align:right>41</td><td style=text-align:left>1990s</td></tr><tr><td style=text-align:right>6</td><td style=text-align:left>Nightwish</td><td style=text-align:left>Angels Fall First</td><td style=text-align:left>Nymphomaniac Fantasia</td><td style=text-align:left>The scent</td><td style=text-align:right>1996</td><td style=text-align:left>[&lsquo;scent&rsquo;, &lsquo;woman&rsquo;, &lsquo;&mldr;&rsquo;]</td><td style=text-align:right>29</td><td style=text-align:right>28</td><td style=text-align:left>1990s</td></tr><tr><td style=text-align:right>7</td><td style=text-align:left>Nightwish</td><td style=text-align:left>Angels Fall First</td><td style=text-align:left>Know Why The Nightingale Sings</td><td style=text-align:left>What does</td><td style=text-align:right>1996</td><td style=text-align:left>[&lsquo;fall&rsquo;, &lsquo;feel&rsquo;, &lsquo;boy&rsquo;, &mldr;]</td><td style=text-align:right>49</td><td style=text-align:right>47</td><td style=text-align:left>1990s</td></tr><tr><td style=text-align:right>8</td><td style=text-align:left>Nightwish</td><td style=text-align:left>Angels Fall First</td><td style=text-align:left>Lappi (Lapland)</td><td style=text-align:left>Part 1: Er</td><td style=text-align:right>1996</td><td style=text-align:left>[&rsquo;erämaajärvi&rsquo;, &lsquo;kautta&rsquo;, &rsquo;erämaajärven&rsquo;, &mldr;]</td><td style=text-align:right>63</td><td style=text-align:right>54</td><td style=text-align:left>1990s</td></tr><tr><td style=text-align:right>9</td><td style=text-align:left>Nightwish</td><td style=text-align:left>Angels Fall First</td><td style=text-align:left>Once Upon A Troubadour</td><td style=text-align:left>A lonely b</td><td style=text-align:right>1996</td><td style=text-align:left>[&rsquo;lone&rsquo;, &lsquo;bard&rsquo;, &lsquo;wander&rsquo;, &mldr;]</td><td style=text-align:right>91</td><td style=text-align:right>62</td><td style=text-align:left>1990s</td></tr></tbody></table><h2 id=explore-relationship>Explore relationship<a hidden class=anchor aria-hidden=true href=#explore-relationship>#</a></h2><p>From this plot, I can see that there is a correlation between <code>word_count</code> and <code>unique_word_count</code>, that is, they go in the same direction. The higher the word_count, the higher unique_word_count and vice versa.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>g <span style=color:#f92672>=</span> sns<span style=color:#f92672>.</span>PairGrid(df[[<span style=color:#e6db74>&#39;word_count&#39;</span>, <span style=color:#e6db74>&#39;unique_word_count&#39;</span>]])
</span></span><span style=display:flex><span>g<span style=color:#f92672>.</span>map(plt<span style=color:#f92672>.</span>scatter)
</span></span></code></pre></div><p><img loading=lazy src=/images/2021-08-18-19-02-25.png alt></p><h2 id=boxplot>Boxplot<a hidden class=anchor aria-hidden=true href=#boxplot>#</a></h2><p>We can use either <code>word_count</code> or <code>unique_word_count</code>, since they go in the same direction, except the values from <code>unique_word_count</code> will be higher, but it is proportional to <code>word_count</code></p><p>Boxplot represents data distribution in quartiles, in which the the box-y area is in middle of the distribution (think of a bell curve, the box-y area is right around the peak, padded a bit to left and right), and the line-y area is the left/right edge of the curve. The scattered points are outliers, meaning they are too different from the rest of the dataset.</p><p>From this figure, I can see that Nightwish has a very large outlier, seeing one data point is in 350 range. Myrath has the least words, and Linkin Park has the most. For Linkin Park, it can be attributed to the fact that their lyrics contain rap verses. As for Nightwish outliers, some of their songs contain very lengthy spoken parts.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>plt<span style=color:#f92672>.</span>figure(figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>10</span>,<span style=color:#ae81ff>7</span>))
</span></span><span style=display:flex><span>sns<span style=color:#f92672>.</span>boxplot(x<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;word_count&#34;</span>, y<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;artist&#34;</span>, data<span style=color:#f92672>=</span>df, orient<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;h&#39;</span>)
</span></span></code></pre></div><p><img loading=lazy src=/images/2021-08-18-19-02-38.png alt></p><h2 id=most-common-words>Most common words<a hidden class=anchor aria-hidden=true href=#most-common-words>#</a></h2><p>In this step, I count how many times a word occur per dataset, then plot a bar graph for each. For the bands I usually listen to, each album has a theme, so it&rsquo;s very probable that each album would have different set of most common words.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>word_vector</span>(df):
</span></span><span style=display:flex><span>    <span style=color:#75715e>########## make a list of all unique words</span>
</span></span><span style=display:flex><span>    all_words <span style=color:#f92672>=</span> []
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> df<span style=color:#f92672>.</span>tokens:
</span></span><span style=display:flex><span>        all_words<span style=color:#f92672>.</span>extend(set(i))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    all_words <span style=color:#f92672>=</span> set(all_words)
</span></span><span style=display:flex><span>    <span style=color:#75715e>########## make tf/idf</span>
</span></span><span style=display:flex><span>    word_count <span style=color:#f92672>=</span> df<span style=color:#f92672>.</span>tokens<span style=color:#f92672>.</span>apply(<span style=color:#66d9ef>lambda</span> x: Counter(x))
</span></span><span style=display:flex><span>    word_count <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>DataFrame(word_count<span style=color:#f92672>.</span>to_list())
</span></span><span style=display:flex><span>    <span style=color:#75715e>########## get sum for each unique word</span>
</span></span><span style=display:flex><span>    wordcount_sum <span style=color:#f92672>=</span> []
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> word_count<span style=color:#f92672>.</span>columns:
</span></span><span style=display:flex><span>        wordcount_sum<span style=color:#f92672>.</span>append({
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#39;word&#39;</span>: i,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#39;count&#39;</span>: word_count[i]<span style=color:#f92672>.</span>sum()
</span></span><span style=display:flex><span>        })
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    wordcount_sum <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>DataFrame(wordcount_sum)
</span></span><span style=display:flex><span>    wordcount_sum <span style=color:#f92672>=</span> wordcount_sum[wordcount_sum[<span style=color:#e6db74>&#39;count&#39;</span>]<span style=color:#f92672>!=</span><span style=color:#ae81ff>0</span>]
</span></span><span style=display:flex><span>    wordcount_sum<span style=color:#f92672>.</span>sort_values(by<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;count&#39;</span>, ascending<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>, inplace<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>    <span style=color:#75715e>##########</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> wordcount_sum<span style=color:#f92672>.</span>head(<span style=color:#ae81ff>10</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>## get wordcount for each group, this way the word_vector function is not getting messy</span>
</span></span><span style=display:flex><span>wordcount_group <span style=color:#f92672>=</span> []
</span></span><span style=display:flex><span><span style=color:#75715e>################## adjust filters here</span>
</span></span><span style=display:flex><span>artist <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;Epica&#39;</span>
</span></span><span style=display:flex><span>group <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;album&#39;</span> <span style=color:#75715e># album, decade</span>
</span></span><span style=display:flex><span><span style=color:#75715e>##################</span>
</span></span><span style=display:flex><span>df_temp <span style=color:#f92672>=</span> df[df<span style=color:#f92672>.</span>artist<span style=color:#f92672>==</span>artist]
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> df_temp[group]<span style=color:#f92672>.</span>unique():
</span></span><span style=display:flex><span>    chunk <span style=color:#f92672>=</span> word_vector(df_temp[df[group]<span style=color:#f92672>==</span>i])
</span></span><span style=display:flex><span>    chunk[group] <span style=color:#f92672>=</span> i
</span></span><span style=display:flex><span>    wordcount_group<span style=color:#f92672>.</span>append(chunk)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>wordcount_group <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>concat(wordcount_group)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>## plot</span>
</span></span><span style=display:flex><span>fig, axs <span style=color:#f92672>=</span> plt<span style=color:#f92672>.</span>subplots(len(wordcount_group[group]<span style=color:#f92672>.</span>unique()), figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>13</span>,<span style=color:#ae81ff>53</span>)) <span style=color:#75715e># adjust figure size here if it&#39;s too cramped</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> index, i <span style=color:#f92672>in</span> enumerate(wordcount_group[group]<span style=color:#f92672>.</span>unique()):
</span></span><span style=display:flex><span>    temp <span style=color:#f92672>=</span> wordcount_group[wordcount_group[group]<span style=color:#f92672>==</span>i]
</span></span><span style=display:flex><span>    axs[index]<span style=color:#f92672>.</span>bar(temp[<span style=color:#e6db74>&#39;word&#39;</span>], temp[<span style=color:#e6db74>&#39;count&#39;</span>])
</span></span><span style=display:flex><span>    axs[index]<span style=color:#f92672>.</span>set_title(i)
</span></span></code></pre></div><p><img loading=lazy src=/images/2021-08-18-19-02-53.png alt></p><p>From the above image, you can see that the top words don&rsquo;t vary much between albums. So I can conclude that Epica have a consistent lyric themes, but if you listen you can hear that their melody changes every album. For instance, in The Divine Conspiracy, it&rsquo;s very classical and oriental oriented, but in The Holographic Principle it gets heavier.</p><p>But that&rsquo;s only variations between albums from one artist. What if we do the same but with each artist instead?</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>wordcount_group <span style=color:#f92672>=</span> []
</span></span><span style=display:flex><span>df_temp <span style=color:#f92672>=</span> df
</span></span><span style=display:flex><span>group <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;artist&#39;</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> df_temp[group]<span style=color:#f92672>.</span>unique():
</span></span><span style=display:flex><span>    chunk <span style=color:#f92672>=</span> word_vector(df_temp[df[group]<span style=color:#f92672>==</span>i])
</span></span><span style=display:flex><span>    chunk[group] <span style=color:#f92672>=</span> i
</span></span><span style=display:flex><span>    wordcount_group<span style=color:#f92672>.</span>append(chunk)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>wordcount_group <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>concat(wordcount_group)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>fig, axs <span style=color:#f92672>=</span> plt<span style=color:#f92672>.</span>subplots(len(wordcount_group[group]<span style=color:#f92672>.</span>unique()), figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>13</span>,<span style=color:#ae81ff>80</span>)) <span style=color:#75715e># adjust figure size here if it&#39;s too cramped</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> index, i <span style=color:#f92672>in</span> enumerate(wordcount_group[group]<span style=color:#f92672>.</span>unique()):
</span></span><span style=display:flex><span>    temp <span style=color:#f92672>=</span> wordcount_group[wordcount_group[group]<span style=color:#f92672>==</span>i]
</span></span><span style=display:flex><span>    axs[index]<span style=color:#f92672>.</span>bar(temp[<span style=color:#e6db74>&#39;word&#39;</span>], temp[<span style=color:#e6db74>&#39;count&#39;</span>])
</span></span><span style=display:flex><span>    axs[index]<span style=color:#f92672>.</span>set_title(i)
</span></span></code></pre></div><p><img loading=lazy src=/images/2021-08-18-19-03-11.png alt></p><p>Whoops. Still more or less the same. But if you look carefully, Powerwolf stands out because their lyrical themes are werewolves and myths.</p><h2 id=topic-modeling>Topic modeling<a hidden class=anchor aria-hidden=true href=#topic-modeling>#</a></h2><p>So I change the tactics a bit by using topic modeling instead of seeing just the top words count. This way, the model and extract group of words that said to be the essence belonging to each cluster. I use both NMF and LDA here for comparison. Here, I tell the model to read lyrics from four artists, then try to group into clusters and finding main words from each, but I&rsquo;m not telling it which document belongs to which artist.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>display_topics</span>(model, feature_names, no_top_words):
</span></span><span style=display:flex><span>    topic_words <span style=color:#f92672>=</span> []
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> topic_idx, topic <span style=color:#f92672>in</span> enumerate(model<span style=color:#f92672>.</span>components_):
</span></span><span style=display:flex><span>        print (<span style=color:#e6db74>&#34;Topic </span><span style=color:#e6db74>%d</span><span style=color:#e6db74>:&#34;</span> <span style=color:#f92672>%</span> (topic_idx))
</span></span><span style=display:flex><span>        topic <span style=color:#f92672>=</span> (<span style=color:#e6db74>&#34; &#34;</span><span style=color:#f92672>.</span>join([feature_names[i] <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> topic<span style=color:#f92672>.</span>argsort()[:<span style=color:#f92672>-</span>no_top_words <span style=color:#f92672>-</span> <span style=color:#ae81ff>1</span>:<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>]]))
</span></span><span style=display:flex><span>        print(<span style=color:#e6db74>&#39;</span><span style=color:#ae81ff>\t</span><span style=color:#e6db74>&#39;</span> <span style=color:#f92672>+</span> topic)
</span></span><span style=display:flex><span>        topic_words<span style=color:#f92672>.</span>append(topic)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> topic_words
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>## define temp dataframe here</span>
</span></span><span style=display:flex><span>temp <span style=color:#f92672>=</span> df<span style=color:#f92672>.</span>query(<span style=color:#e6db74>&#39;artist == &#34;Visions of Atlantis&#34; or</span><span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span><span style=color:#e6db74>                artist == &#34;Lacuna Coil&#34; or</span><span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span><span style=color:#e6db74>                artist == &#34;Epica&#34; or</span><span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span><span style=color:#e6db74>                artist == &#34;Nightwish&#34;&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>## define parameters</span>
</span></span><span style=display:flex><span>no_features <span style=color:#f92672>=</span> <span style=color:#ae81ff>1000</span>
</span></span><span style=display:flex><span>no_topics <span style=color:#f92672>=</span> len(temp<span style=color:#f92672>.</span>artist<span style=color:#f92672>.</span>unique()) <span style=color:#75715e># set album count as number of topics</span>
</span></span><span style=display:flex><span>no_top_words <span style=color:#f92672>=</span> <span style=color:#ae81ff>15</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>## create word matrix</span>
</span></span><span style=display:flex><span>tfidf_vectorizer <span style=color:#f92672>=</span> TfidfVectorizer(max_df<span style=color:#f92672>=</span><span style=color:#ae81ff>0.95</span>, min_df<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>, max_features<span style=color:#f92672>=</span>no_features, stop_words<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;english&#39;</span>)
</span></span><span style=display:flex><span>tfidf <span style=color:#f92672>=</span> tfidf_vectorizer<span style=color:#f92672>.</span>fit_transform(temp<span style=color:#f92672>.</span>lyrics)
</span></span><span style=display:flex><span>tfidf_feature_names <span style=color:#f92672>=</span> tfidf_vectorizer<span style=color:#f92672>.</span>get_feature_names()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#39;========== NMF ==========&#39;</span>)
</span></span><span style=display:flex><span>nmf <span style=color:#f92672>=</span> NMF(n_components<span style=color:#f92672>=</span>no_topics, random_state<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>, alpha<span style=color:#f92672>=</span><span style=color:#ae81ff>.1</span>, l1_ratio<span style=color:#f92672>=</span><span style=color:#ae81ff>.5</span>, init<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;nndsvd&#39;</span>)<span style=color:#f92672>.</span>fit(tfidf)
</span></span><span style=display:flex><span>topic_words <span style=color:#f92672>=</span> display_topics(nmf, tfidf_feature_names, no_top_words)
</span></span></code></pre></div><pre><code>========== NMF ==========
Topic 0:
	ll time life way light come live free just feel inside ve day let world
Topic 1:
	love heart night wish forever hate soul dream oh art rest heaven need kiss lust
Topic 2:
	away run far stay inside journey dream fade just wash felt destruction escape falling walked
Topic 3:
	don know wanna want just feel say care hate goes cause liar let look reason
</code></pre><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>print(<span style=color:#e6db74>&#39;========== LDA ==========&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>lda <span style=color:#f92672>=</span> LatentDirichletAllocation(n_components<span style=color:#f92672>=</span>no_topics, max_iter<span style=color:#f92672>=</span><span style=color:#ae81ff>5</span>, learning_method<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;online&#39;</span>, learning_offset<span style=color:#f92672>=</span><span style=color:#ae81ff>50.</span>,random_state<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>)<span style=color:#f92672>.</span>fit(tfidf)
</span></span><span style=display:flex><span>topic_words <span style=color:#f92672>=</span> display_topics(lda, tfidf_feature_names, no_top_words)
</span></span></code></pre></div><pre><code>========== LDA ==========
Topic 0:
	distance don beautiful let today cold look guide read world way faith wish mind heart
Topic 1:
	est tale feels talking drives wall wishmaster disciple bone mad searching free master apprentice sing
Topic 2:
	love heart ll hearts time world fight let come night know shadows try eyes mind
Topic 3:
	leaving ll healing endless sed died walk desire life nos ne moment die nostra like
</code></pre><p>From NMF, I can tell that:</p><ul><li>Topic 0 is Epica</li><li>Topic 1 is Nightwish</li><li>Topic 2 is Visions of Atlantis</li><li>Topic 3 is Lacuna Coil</li></ul><p>I think NMF performs better in this case 😆</p><p>There are some instances LDA performs better, but generally unless it&rsquo;s very obvious from the start, sometimes you use different models and see which performs best for a given dataset.</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://www.karnwong.me/tags/data-analysis/>data analysis</a></li></ul><nav class=paginav><a class=prev href=https://www.karnwong.me/posts/2020/05/impute-pipelines/><span class=title>« Prev</span><br><span>Impute pipelines</span></a>
<a class=next href=https://www.karnwong.me/posts/2020/01/yuuemuue-ngaithykinkluuetnaimaidchaanglambaak/><span class=title>Next »</span><br><span>อยู่เมืองไทยกินกลูเตนไม่ได้ช่างลำบาก</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2023 <a href=https://www.karnwong.me/>Karn Wong</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>